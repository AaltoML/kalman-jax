import jax.numpy as np
from jax.scipy.special import erf, erfc, gammaln
from jax.nn import softplus
from jax import jit, partial, random
from numpy.polynomial.hermite import hermgauss
from utils import logphi
pi = 3.141592653589793


class Likelihood(object):
    """
    The likelihood model class, p(y‚Çô|f‚Çô). Each likelihood implements its own moment matching method,
    which calculates the log partition function, logZ‚Çô, and its derivatives w.r.t. the cavity mean m‚Çô,
        logZ‚Çô = log ‚à´ p(y‚Çô|f‚Çô) ùìù(f‚Çô|m‚Çô,v‚Çô) df‚Çô = E[p(y‚Çô|f‚Çô)]
    If no custom moment matching method is provided, Gauss-Hermite quadrature is used by default.
    The requirement for quadrature is simply a method called evaluate_likelihood(), which computes
    the likelihood model p(y‚Çô|f‚Çô) for given data and function values.
    """
    def __init__(self, hyp=None):
        """
        :param hyp: (hyper)parameters of the likelihood model
        """
        self.hyp = hyp

    def evaluate_likelihood(self, y, f, hyp=None):
        raise NotImplementedError('direct evaluation of this likelihood is not implemented')

    def evaluate_log_likelihood(self, y, f, hyp=None):
        raise NotImplementedError('direct evaluation of this log-likelihood is not implemented')

    # @partial(jit, static_argnums=(0, 5, 6, 7))
    # def site_update(self, y, m, v, hyp=None, site_update=True, ep_fraction=1.0):
    #     if inf is 'EP' or inf is 'ADF':
    #         outputs = self.moment_match(y, m, v, hyp, site_update, ep_fraction)
    #     elif inf is 'PL':
    #         outputs = self.statistical_linear_regression(y, m, v, hyp, site_update, ep_fraction)
    #     else:
    #         raise NotImplementedError('inference method not implemented')
    #     return outputs

    @partial(jit, static_argnums=(0, 5))
    def moment_match_quadrature(self, y, m, v, hyp=None, site_update=True, ep_fraction=1.0, num_quad_points=20):
        """
        Perform moment matching via Gauss-Hermite quadrature.
        Moment matching invloves computing the log partition function, logZ‚Çô, and its derivatives w.r.t. the cavity mean
            logZ‚Çô = log ‚à´ p·µÉ(y‚Çô|f‚Çô) ùìù(f‚Çô|m‚Çô,v‚Çô) df‚Çô
        with EP power a.
        :param y: observed data (y‚Çô) [scalar]
        :param m: cavity mean (m‚Çô) [scalar]
        :param v: cavity variance (v‚Çô) [scalar]
        :param hyp: likelihood hyperparameter [scalar]
        :param site_update: if True, return the updated site parameters [bool]
        :param ep_fraction: EP power / fraction (a) [scalar]
        :param num_quad_points: the number of Gauss-Hermite sigma points to use during quadrature [scalar]
        :return:
            lZ: the log partition function, logZ‚Çô  [scalar]
            dlZ: first derivative of logZ‚Çô w.r.t. m‚Çô (if derivatives=True)  [scalar]
            d2lZ: second derivative of logZ‚Çô w.r.t. m‚Çô (if derivatives=True)  [scalar]
        """
        x, w = hermgauss(num_quad_points)  # Gauss-Hermite sigma points and weights
        w = w / np.sqrt(pi)  # scale weights by 1/‚àöœÄ
        sigma_points = np.sqrt(2) * np.sqrt(v) * x + m  # scale locations according to cavity dist.
        # pre-compute w·µ¢ p·µÉ(y‚Çô|x·µ¢‚àö(2v‚Çô) + m‚Çô)
        weighted_likelihood_eval = w * self.evaluate_likelihood(y, sigma_points, hyp) ** ep_fraction

        # a different approach, based on the log-likelihood, which can be more stable:
        # ll = self.evaluate_log_likelihood(y, sigma_points)
        # lmax = np.max(ll)
        # weighted_likelihood_eval = np.exp(lmax * ep_fraction) * w * np.exp(ep_fraction * (ll - lmax))

        # Compute partition function via quadrature:
        # Z‚Çô = ‚à´ p·µÉ(y‚Çô|f‚Çô) ùìù(f‚Çô|m‚Çô,v‚Çô) df‚Çô
        #    ‚âà ‚àë·µ¢ w·µ¢ p·µÉ(y‚Çô|x·µ¢‚àö(2v‚Çô) + m‚Çô)
        Z = np.sum(
            weighted_likelihood_eval
        )
        lZ = np.log(Z)
        if site_update:
            Zinv = 1.0 / Z
            # Compute derivative of partition function via quadrature:
            # dZ‚Çô/dm‚Çô = ‚à´ (f‚Çô-m‚Çô) v‚Çô‚Åª¬π p·µÉ(y‚Çô|f‚Çô) ùìù(f‚Çô|m‚Çô,v‚Çô) df‚Çô
            #         ‚âà ‚àë·µ¢ w·µ¢ (f‚Çô-m‚Çô) v‚Çô‚Åª¬π p·µÉ(y‚Çô|x·µ¢‚àö(2v‚Çô) + m‚Çô)
            dZ = np.sum(
                (sigma_points - m) / v
                * weighted_likelihood_eval
            )
            # dlogZ‚Çô/dm‚Çô = (dZ‚Çô/dm‚Çô) / Z‚Çô
            dlZ = Zinv * dZ
            # Compute second derivative of partition function via quadrature:
            # d¬≤Z‚Çô/dm‚Çô¬≤ = ‚à´ [(f‚Çô-m‚Çô)¬≤ v‚Çô‚Åª¬≤ - v‚Çô‚Åª¬π] p·µÉ(y‚Çô|f‚Çô) ùìù(f‚Çô|m‚Çô,v‚Çô) df‚Çô
            #           ‚âà ‚àë·µ¢ w·µ¢ [(f‚Çô-m‚Çô)¬≤ v‚Çô‚Åª¬≤ - v‚Çô‚Åª¬π] p·µÉ(y‚Çô|x·µ¢‚àö(2v‚Çô) + m‚Çô)
            d2Z = np.sum(
                ((sigma_points - m) ** 2 / v ** 2 - 1.0 / v)
                * weighted_likelihood_eval
            )
            # d¬≤logZ‚Çô/dm‚Çô¬≤ = d[(dZ‚Çô/dm‚Çô) / Z‚Çô]/dm‚Çô
            #              = (d¬≤Z‚Çô/dm‚Çô¬≤ * Z‚Çô - (dZ‚Çô/dm‚Çô)¬≤) / Z‚Çô¬≤
            #              = d¬≤Z‚Çô/dm‚Çô¬≤ / Z‚Çô - (dlogZ‚Çô/dm‚Çô)¬≤
            d2lZ = -dlZ ** 2 + Zinv * d2Z
            site_mean = m - dlZ / d2lZ  # approx. likelihood (site) mean (see Rasmussen & Williams p75)
            site_var = -ep_fraction * (v + 1 / d2lZ)  # approx. likelihood (site) variance
            return lZ, site_mean, site_var
        else:
            return lZ

    @partial(jit, static_argnums=(0, 5))
    def moment_match(self, y, m, v, hyp=None, site_update=True, ep_fraction=1.0):
        """
        If no custom moment matching method is provided, we use Gauss-Hermite quadrature.
        """
        return self.moment_match_quadrature(y, m, v, hyp, site_update, ep_fraction=ep_fraction)

    @staticmethod
    def link_fn(latent_mean):
        return latent_mean

    @staticmethod
    @jit
    def sample_noise(latent_mean, likelihood_var):
        lik_std = np.sqrt(likelihood_var)
        # gaussian_sample = latent_mean + lik_std[..., np.newaxis] * nprandom.normal(size=latent_mean.shape)
        gaussian_sample = latent_mean + lik_std[..., np.newaxis] * random.normal(random.PRNGKey(123),
                                                                                 shape=latent_mean.shape)
        return gaussian_sample


class Gaussian(Likelihood):
    """
    The Gaussian likelihood:
        p(y‚Çô|f‚Çô) = ùìù(y‚Çô|f‚Çô,œÉ¬≤)
    """
    def __init__(self, hyp):
        """
        :param hyp: The observation noise variance, œÉ¬≤
        """
        super().__init__(hyp=hyp)
        if self.hyp is None:
            print('using default likelihood parameter since none was supplied')
            self.hyp = -2.25  # softplus(-2.25) ~= 0.1
        self.name = 'Gaussian'

    @partial(jit, static_argnums=0)
    def evaluate_likelihood(self, y, f, hyp=None):
        """
        Evaluate the Gaussian function ùìù(y‚Çô|f‚Çô,œÉ¬≤).
        Can be used to evaluate Q quadrature points.
        :param y: observed data y‚Çô [scalar]
        :param f: mean, i.e. the latent function value f‚Çô [Q, 1]
        :param hyp: likelihood variance œÉ¬≤ [scalar]
        :return:
            ùìù(y‚Çô|f‚Çô,œÉ¬≤), where œÉ¬≤ is the observation noise [Q, 1]
        """
        if hyp is None:
            hyp = softplus(self.hyp)
        return (2 * pi * hyp) ** -0.5 * np.exp(-0.5 * (y - f) ** 2 / hyp)

    @partial(jit, static_argnums=0)
    def evaluate_log_likelihood(self, y, f, hyp=None):
        """
        Evaluate the log-Gaussian function logùìù(y‚Çô|f‚Çô,œÉ¬≤).
        Can be used to evaluate Q quadrature points.
        :param y: observed data y‚Çô [scalar]
        :param f: mean, i.e. the latent function value f‚Çô [Q, 1]
        :param hyp: likelihood variance œÉ¬≤ [scalar]
        :return:
            logùìù(y‚Çô|f‚Çô,œÉ¬≤), where œÉ¬≤ is the observation noise [Q, 1]
        """
        if hyp is None:
            hyp = softplus(self.hyp)
        return -0.5 * np.log(2 * pi * hyp) - 0.5 * (y - f) ** 2 / hyp

    @partial(jit, static_argnums=(0, 5))
    def moment_match(self, y, m, v, hyp=None, site_update=True, ep_fraction=1.0):
        """
        Closed form Gaussian moment matching.
        Calculates the log partition function of the EP tilted distribution:
            logZ‚Çô = log ‚à´ ùìù·µÉ(y‚Çô|f‚Çô,œÉ¬≤) ùìù(f‚Çô|m‚Çô,v‚Çô) df‚Çô = E[ùìù(y‚Çô|f‚Çô,œÉ¬≤)]
        and its derivatives w.r.t. m‚Çô, which are required for moment matching.
        :param y: observed data (y‚Çô) [scalar]
        :param m: cavity mean (m‚Çô) [scalar]
        :param v: cavity variance (v‚Çô) [scalar]
        :param hyp: observation noise variance (œÉ¬≤) [scalar]
        :param site_update: if True, return the derivatives of the log partition function w.r.t. m‚Çô [bool]
        :param ep_fraction: EP power / fraction (a) [scalar]
        :return:
            lZ: the log partition function, logZ‚Çô [scalar]
            dlZ: first derivative of logZ‚Çô w.r.t. m‚Çô (if derivatives=True) [scalar]
            d2lZ: second derivative of logZ‚Çô w.r.t. m‚Çô (if derivatives=True) [scalar]
        """
        if hyp is None:
            hyp = softplus(self.hyp)
        # log partition function, lZ:
        # logZ‚Çô = log ‚à´ ùìù·µÉ(y‚Çô|f‚Çô,œÉ¬≤) ùìù(f‚Çô|m‚Çô,v‚Çô) df‚Çô
        #       = log ‚àö(2œÄœÉ¬≤)¬π‚Åª·µÉ ‚à´ ùìù(y‚Çô|f‚Çô,œÉ¬≤/a) ùìù(f‚Çô|m‚Çô,v‚Çô) df‚Çô
        #       = (1-a)/2 log 2œÄœÉ¬≤ + log ùìù(y‚Çô|m‚Çô,œÉ¬≤/a+v‚Çô)
        lZ = (
                (1 - ep_fraction) / 2 * np.log(2 * pi * hyp)
                - (y - m) ** 2 / (hyp / ep_fraction + v) / 2
                - np.log(np.maximum(2 * pi * (hyp / ep_fraction + v), 1e-10)) / 2
        )
        if site_update:
            # dlogZ‚Çô/dm‚Çô = (y‚Çô - m‚Çô)(œÉ¬≤/a + v‚Çô)‚Åª¬π
            dlZ = (y - m) / (hyp / ep_fraction + v)  # 1st derivative w.r.t. mean
            # d¬≤logZ‚Çô/dm‚Çô¬≤ = -(œÉ¬≤/a + v‚Çô)‚Åª¬π
            d2lZ = -1 / (hyp / ep_fraction + v)  # 2nd derivative w.r.t. mean
            site_mean = m - dlZ / d2lZ  # approx. likelihood (site) mean (see Rasmussen & Williams p75)
            site_var = -ep_fraction * (v + 1 / d2lZ)  # approx. likelihood (site) variance
            return lZ, site_mean, site_var
        else:
            return lZ


class Probit(Likelihood):
    """
    The Probit Binary Classification likelihood, i.e. the Error Function Likelihood,
    i.e. the Gaussian (Normal) cumulative density function:
        p(y‚Çô|f‚Çô) = Œ¶(y‚Çôf‚Çô)
                 = ‚à´ ùìù(x|0,1) dx, where the integral is over (-‚àû, f‚Çôy‚Çô],
    and where we force the data to be +/-1: y‚Çô œµ {-1, +1}.
    The Normal CDF is calulcated using the error function:
        Œ¶(y‚Çôf‚Çô) = (1 + erf(y‚Çôf‚Çô / ‚àö2)) / 2
    for erf(z) = (2/‚àöœÄ) ‚à´ exp(-x¬≤) dx, where the integral is over [0, z]
    """
    def __init__(self, hyp):
        """
        :param hyp: None. This likelihood model has no hyperparameters.
        """
        super().__init__(hyp=hyp)
        self.name = 'Probit'

    @staticmethod
    @jit
    def link_fn(latent_mean):
        return erfc(-latent_mean / np.sqrt(2.0)) - 1.0

    def eval(self, mu, var):
        """
        ported from GPML toolbox - not used.
        """
        lp, _, _ = self.moment_match(1, mu, var)
        p = np.exp(lp)
        ymu = 2 * p - 1
        yvar = 4 * p * (1 - p)
        return lp, ymu, yvar

    @partial(jit, static_argnums=0)
    def evaluate_likelihood(self, y, f, hyp=None):
        """
        Evaluate the Gaussian CDF likelihood model,
            Œ¶(y‚Çôf‚Çô) = (1 + erf(y‚Çôf‚Çô / ‚àö2)) / 2
        for erf(z) = (2/‚àöœÄ) ‚à´ exp(-x¬≤) dx, where the integral is over [0, z]
        Can be used to evaluate Q quadrature points when performing moment matching.
        :param y: observed data y‚Çô œµ {-1, +1} [scalar]
        :param f: latent function value f‚Çô [Q, 1]
        :param hyp: dummy input, Probit has no hyperparameters
        :return:
            Œ¶(y‚Çôf‚Çô) [Q, 1]
        """
        return (1.0 + erf(y * f / np.sqrt(2.0))) / 2.0  # Œ¶(z)

    @partial(jit, static_argnums=0)
    def evaluate_log_likelihood(self, y, f, hyp=None):
        """
        Evaluate the Gaussian CDF log-likelihood,
            log Œ¶(y‚Çôf‚Çô) = log[(1 + erf(y‚Çôf‚Çô / ‚àö2)) / 2]
        for erf(z) = (2/‚àöœÄ) ‚à´ exp(-x¬≤) dx, where the integral is over [0, z].
        Can be used to evaluate Q quadrature points when performing moment matching.
        :param y: observed data y‚Çô œµ {-1, +1} [scalar]
        :param f: latent function value f‚Çô [Q, 1]
        :param hyp: dummy input, Probit has no hyperparameters
        :return:
            log Œ¶(y‚Çôf‚Çô) [Q, 1]
        """
        return np.log(1.0 + erf(y * f / np.sqrt(2.0)) + 1e-10) - np.log(2)  # logŒ¶(z)

    @partial(jit, static_argnums=(0, 5, 6))
    def moment_match(self, y, m, v, hyp=None, site_update=True, ep_fraction=1.0):
        """
        Probit likelihood moment matching.
        Calculates the log partition function of the EP tilted distribution:
            logZ‚Çô = log ‚à´ Œ¶·µÉ(y‚Çôf‚Çô) ùìù(f‚Çô|m‚Çô,v‚Çô) df‚Çô
        and its derivatives w.r.t. m‚Çô, which are required for moment matching.
        If the EP fraction a = 1, we get
                  = log Œ¶(y‚Çôz‚Çô), where z‚Çô = m‚Çô / ‚àö(1 + v‚Çô)   [see Rasmussen & Williams p74]
        otherwise we must use quadrature to compute the log partition and its derivatives.
        Note: we enforce y‚Çô œµ {-1, +1}.
        :param y: observed data (y‚Çô) [scalar]
        :param m: cavity mean (m‚Çô) [scalar]
        :param v: cavity variance (v‚Çô) [scalar]
        :param hyp: dummy variable (Probit has no hyperparameters)
        :param site_update: if True, return the derivatives of the log partition function w.r.t. m‚Çô [bool]
        :param ep_fraction: EP power / fraction (a) [scalar]
        :return:
            lZ: the log partition function, logZ‚Çô [scalar]
            dlZ: first derivative of logZ‚Çô w.r.t. m‚Çô (if derivatives=True) [scalar]
            d2lZ: second derivative of logZ‚Çô w.r.t. m‚Çô (if derivatives=True) [scalar]
        """
        y = np.sign(y)  # only allow values of +/-1
        # y[np.where(y == 0)] = -1  # set zeros to -1
        y = np.sign(y - 0.01)  # set zeros to -1
        if ep_fraction == 1:  # if a = 1, we can calculate the moments in closed form
            z = m / np.sqrt(1.0 + v)
            z = z * y  # z‚Çô = y‚Çôm‚Çô / ‚àö(1 + v‚Çô)
            # logZ‚Çô = log ‚à´ Œ¶(y‚Çôf‚Çô) ùìù(f‚Çô|m‚Çô,v‚Çô) df‚Çô
            #       = log Œ¶(y‚Çôm‚Çô/‚àö(1 + v‚Çô))  [see Rasmussen & Williams p74]
            lZ, dlp = logphi(z)
            if site_update:
                # dlogZ‚Çô/dm‚Çô = y‚Çô dlogŒ¶(z‚Çô)/dm‚Çô / ‚àö(1 + v‚Çô)
                dlZ = y * dlp / np.sqrt(1.0 + v)  # first derivative w.r.t m‚Çô
                # d¬≤logZ‚Çô/dm‚Çô¬≤ = -dlogŒ¶(z‚Çô)/dm‚Çô (z‚Çô + dlogŒ¶(z‚Çô)/dm‚Çô) / ‚àö(1 + v‚Çô)
                d2lZ = -dlp * (z + dlp) / (1.0 + v)  # second derivative w.r.t m‚Çô
                site_mean = m - dlZ / d2lZ  # approx. likelihood (site) mean (see Rasmussen & Williams p75)
                site_var = - (v + 1 / d2lZ)  # approx. likelihood (site) variance
                return lZ, site_mean, site_var
            else:
                return lZ
        else:
            # if a is not 1, we can calculate the moments via quadrature
            return self.moment_match_quadrature(y, m, v, None, site_update, ep_fraction)


class Erf(Probit):
    pass


class Poisson(Likelihood):
    """
    The Poisson likelihood:
        p(y‚Çô|f‚Çô) = Poisson(f‚Çô) = Œº ∏ exp(-Œº) / y‚Çô!
    where Œº = g(f‚Çô) = mean = variance is the Poisson intensity.
    y‚Çô is non-negative integer count data.
    No closed form moment matching is available, se we default to using quadrature.

    Letting Zy = gamma(y‚Çô+1) = y‚Çô!, we get log p(y‚Çô|f‚Çô) = log(g(f‚Çô))y‚Çô - g(f‚Çô) - log(Zy)
    The larger the intensity Œº, the stronger the likelihood resembles a Gaussian
    since skewness = 1/sqrt(Œº) and kurtosis = 1/Œº.
    Two possible link functions:
    'exp':      link(f‚Çô) = exp(f‚Çô),         we have p(y‚Çô|f‚Çô) = exp(f‚Çôy‚Çô-exp(f‚Çô))           / Zy.
    'logistic': link(f‚Çô) = log(1+exp(f‚Çô))), we have p(y‚Çô|f‚Çô) = log ∏(1+exp(f‚Çô)))(1+exp(f‚Çô)) / Zy.
    """
    def __init__(self, hyp=None, link='exp'):
        """
        :param hyp: None. This likelihood model has no hyperparameters
        :param link: link function, either 'exp' or 'logistic'
        """
        super().__init__(hyp=hyp)
        if link is 'exp':
            self.link_fn = lambda mu: np.exp(mu)
        elif link is 'logistic':
            self.link_fn = lambda mu: np.log(1.0 + np.exp(mu))
        else:
            raise NotImplementedError('link function not implemented')
        self.name = 'Poisson'

    @partial(jit, static_argnums=0)
    def evaluate_likelihood(self, y, f, hyp=None):
        """
        Evaluate the Poisson likelihood:
            p(y‚Çô|f‚Çô) = Poisson(f‚Çô) = Œº ∏ exp(-Œº) / y‚Çô!
        for Œº = g(f‚Çô), where g() is the link function (exponential or logistic).
        We use the gamma function to evaluate y‚Çô! = gamma(y‚Çô + 1).
        Can be used to evaluate Q quadrature points when performing moment matching.
        :param y: observed data (y‚Çô) [scalar]
        :param f: latent function value (f‚Çô) [Q, 1]
        :param hyp: dummy variable (Poisson has no hyperparameters)
        :return:
            Poisson(f‚Çô) = Œº ∏ exp(-Œº) / y‚Çô! [Q, 1]
        """
        mu = self.link_fn(f)
        return mu**y * np.exp(-mu) / np.exp(gammaln(y + 1))

    @partial(jit, static_argnums=0)
    def evaluate_log_likelihood(self, y, f, hyp=None):
        """
        Evaluate the Poisson log-likelihood:
            log p(y‚Çô|f‚Çô) = log Poisson(f‚Çô) = log(Œº ∏ exp(-Œº) / y‚Çô!)
        for Œº = g(f‚Çô), where g() is the link function (exponential or logistic).
        We use the gamma function to evaluate y‚Çô! = gamma(y‚Çô + 1).
        Can be used to evaluate Q quadrature points when performing moment matching.
        :param y: observed data (y‚Çô) [scalar]
        :param f: latent function value (f‚Çô) [Q, 1]
        :param hyp: dummy variable (Poisson has no hyperparameters)
        :return:
            log Poisson(f‚Çô) = log(Œº ∏ exp(-Œº) / y‚Çô!) [Q, 1]
        """
        mu = self.link_fn(f)
        return y * np.log(mu) - mu - gammaln(y + 1)
