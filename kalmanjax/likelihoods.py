import jax.numpy as np
from jax.scipy.special import erf, erfc, gammaln
from jax.nn import softplus
from jax import jit
# from numpy import random as nprandom
from jax import random
pi = 3.141592653589793


class Likelihood(object):
    """
    The likelihood model class, p(yâ‚™|fâ‚™). Each likelihood implements its own moment matching method,
    which calculates the log partition function, logZâ‚™, and its derivatives w.r.t. the cavity mean mâ‚™,
        logZâ‚™ = log âˆ« p(yâ‚™|fâ‚™) ğ“(fâ‚™|mâ‚™,vâ‚™) dfâ‚™ = E[p(yâ‚™|fâ‚™)]
    If no custom moment matching method is provided, Gauss-Hermite quadrature is used by default.
    The requirement for quadrature is simply a method called evaluate_likelihood(), which computes
    the likelihood model p(yâ‚™|fâ‚™) for given data and function values
    """
    def __init__(self, hyp=None):
        """
        :param hyp: (hyper)parameters of the likelihood model
        """
        self.hyp = hyp

    def evaluate_likelihood(self, y, f):
        raise NotImplementedError('direct evaluation of this likelihood is not implemented')

    def evaluate_log_likelihood(self, y, f):
        raise NotImplementedError('direct evaluation of this log-likelihood is not implemented')

    # def moment_match(self, y, mu, var, var_y, derivatives=True):
    @staticmethod
    def moment_match(y, mu, var, hyp, derivatives=True):
        """
        Moment matching invloves computing the log partition function, logZâ‚™, and its derivatives w.r.t. the cavity mean
            logZâ‚™ = log âˆ« p(yâ‚™|fâ‚™) ğ“(fâ‚™|mâ‚™,vâ‚™) dfâ‚™ = E[p(yâ‚™|fâ‚™)]
        which is equivalent to the expectation w.r.t the cavity
        """
        raise NotImplementedError('moment matching not implemented for this likelihood')

    @staticmethod
    def link_fn(latent_mean):
        return latent_mean

    @staticmethod
    @jit
    def sample_noise(latent_mean, likelihood_var):
        lik_std = np.sqrt(likelihood_var)
        # gaussian_sample = latent_mean + lik_std[..., np.newaxis] * nprandom.normal(size=latent_mean.shape)
        gaussian_sample = latent_mean + lik_std[..., np.newaxis] * random.normal(random.PRNGKey(123),
                                                                                 shape=latent_mean.shape)
        return gaussian_sample


class Gaussian(Likelihood):
    """
    The Gaussian likelihood:
        p(yâ‚™|fâ‚™) = ğ“(yâ‚™|fâ‚™,ÏƒÂ²)
    """
    def __init__(self, hyp):
        """
        :param hyp: The observation noise variance, ÏƒÂ²
        """
        super().__init__(hyp=hyp)
        if self.hyp is None:
            print('using default likelihood parameter since none was supplied')
            self.hyp = -2.25  # softplus(-2.25) ~= 0.1

    def evaluate_likelihood(self, y, f):
        """
        Evaluate the Gaussian function ğ“(yâ‚™|fâ‚™,ÏƒÂ²)
        Can be used to evaluate Q quadrature points
        :param y: observed data yâ‚™ [scalar]
        :param f: mean, i.e. the latent function value fâ‚™ [Q, 1]
        :return:
            ğ“(yâ‚™|fâ‚™,ÏƒÂ²), where ÏƒÂ² is the observation noise [Q, 1]
        """
        return (2 * pi * self.hyp) ** -0.5 * np.exp(-0.5 * (y - f) ** 2 / self.hyp)

    def evaluate_log_likelihood(self, y, f):
        """
        Evaluate the log-Gaussian function logğ“(yâ‚™|fâ‚™,ÏƒÂ²)
        Can be used to evaluate Q quadrature points
        :param y: observed data yâ‚™ [scalar]
        :param f: mean, i.e. the latent function value fâ‚™ [Q, 1]
        :return:
            logğ“(yâ‚™|fâ‚™,ÏƒÂ²), where ÏƒÂ² is the observation noise [Q, 1]
        """
        return -0.5 * np.log(2 * pi * self.hyp) - 0.5 * (y - f) ** 2 / self.hyp

    @staticmethod
    @jit
    def moment_match(y, m, v, hyp, derivatives=True):
        """
        Closed form Gaussian moment matching.
        Calculates the log partition function of the EP tilted distribution:
            logZâ‚™ = log âˆ« ğ“(yâ‚™|fâ‚™,ÏƒÂ²) ğ“(fâ‚™|mâ‚™,vâ‚™) dfâ‚™ = E[ğ“(yâ‚™|fâ‚™,ÏƒÂ²)]
        and its derivatives w.r.t. mâ‚™, which are required for moment matching.
        :param y: observed data (yâ‚™) [scalar]
        :param m: cavity mean (mâ‚™) [scalar]
        :param v: cavity variance (vâ‚™) [scalar]
        :param hyp: observation noise variance (ÏƒÂ²) [scalar]
        :param derivatives: if True, return the derivatives of the log partition function w.r.t. mâ‚™ [bool]
        :return:
            lZ: the log partition function, logZâ‚™ [scalar]
            dlZ: first derivative of logZâ‚™ w.r.t. mâ‚™ (if derivatives=True) [scalar]
            d2lZ: second derivative of logZâ‚™ w.r.t. mâ‚™ (if derivatives=True) [scalar]
        """
        # log partition function, lZ:
        # logZâ‚™ = log âˆ« ğ“(yâ‚™|fâ‚™,ÏƒÂ²) ğ“(fâ‚™|mâ‚™,vâ‚™) dfâ‚™
        #       = log ğ“(yâ‚™|mâ‚™,ÏƒÂ²+vâ‚™)
        lZ = (
                - (y - m) ** 2 / (hyp + v) / 2
                - np.log(np.maximum(2 * pi * (hyp + v), 1e-10)) / 2
        )
        if derivatives:
            # dlogZâ‚™/dmâ‚™ = (yâ‚™ - mâ‚™)(ÏƒÂ² + vâ‚™)â»Â¹
            dlZ = (y - m) / (hyp + v)  # 1st derivative w.r.t. mean
            # dÂ²logZâ‚™/dmâ‚™Â² = -(ÏƒÂ² + vâ‚™)â»Â¹
            d2lZ = -1 / (hyp + v)  # 2nd derivative w.r.t. mean
            return lZ, dlZ, d2lZ
        else:
            return lZ


class Probit(Likelihood):
    """
    The Probit Binary Classification likelihood, i.e. the Error Function Likelihood,
    i.e. the Gaussian (Normal) cumulative density function:
        p(yâ‚™|fâ‚™) = Î¦(yâ‚™fâ‚™)
                 = âˆ« ğ“(x|0,1) dx, where the integral is over (-âˆ, fâ‚™yâ‚™],
    and where we force the data to be +/-1: yâ‚™ Ïµ {-1, +1}
    The Normal CDF is calulcated using the error function:
        Î¦(yâ‚™fâ‚™) = (1 + erf(yâ‚™fâ‚™ / âˆš2)) / 2
    for erf(z) = (2/âˆšÏ€) âˆ« exp(-xÂ²) dx, where the integral is over [0, z]
    """
    def __init__(self, hyp):
        """
        :param hyp: None. This likelihood model has no hyperparameters
        """
        super().__init__(hyp=hyp)

    @staticmethod
    @jit
    def link_fn(latent_mean):
        return erfc(-latent_mean / np.sqrt(2.0)) - 1.0

    def eval(self, mu, var):
        """
        ported from GPML toolbox - not used
        """
        lp, _, _ = self.moment_match(1, mu, var)
        p = np.exp(lp)
        ymu = 2 * p - 1
        yvar = 4 * p * (1 - p)
        return lp, ymu, yvar

    def evaluate_likelihood(self, y, f):
        """
        Evaluate the Gaussian CDF likelihood model,
            Î¦(yâ‚™fâ‚™) = (1 + erf(yâ‚™fâ‚™ / âˆš2)) / 2
        for erf(z) = (2/âˆšÏ€) âˆ« exp(-xÂ²) dx, where the integral is over [0, z]
        Can be used to evaluate Q quadrature points when performing moment matching
        :param y: observed data yâ‚™ Ïµ {-1, +1} [scalar]
        :param f: latent function value fâ‚™ [Q, 1]
        :return:
            Î¦(yâ‚™fâ‚™) [Q, 1]
        """
        return (1.0 + erf(y * f / np.sqrt(2.0))) / 2.0  # Î¦(z)

    def evaluate_log_likelihood(self, y, f):
        """
        Evaluate the Gaussian CDF log-likelihood,
            log Î¦(yâ‚™fâ‚™) = log[(1 + erf(yâ‚™fâ‚™ / âˆš2)) / 2]
        for erf(z) = (2/âˆšÏ€) âˆ« exp(-xÂ²) dx, where the integral is over [0, z]
        Can be used to evaluate Q quadrature points when performing moment matching
        :param y: observed data yâ‚™ Ïµ {-1, +1} [scalar]
        :param f: latent function value fâ‚™ [Q, 1]
        :return:
            log Î¦(yâ‚™fâ‚™) [Q, 1]
        """
        return np.log(1.0 + erf(y * f / np.sqrt(2.0)) + 1e-10) - np.log(2)  # logÎ¦(z)

    @staticmethod
    @jit
    def moment_match(y, m, v, hyp=None, derivatives=True):
        """
        Probit likelihood moment matching.
        Calculates the log partition function of the EP tilted distribution:
            logZâ‚™ = log âˆ« Î¦(yâ‚™fâ‚™) ğ“(fâ‚™|mâ‚™,vâ‚™) dfâ‚™
                  = log Î¦(yâ‚™zâ‚™), where zâ‚™ = mâ‚™ / âˆš(1 + vâ‚™)   [see Rasmussen & Williams p74]
        and its derivatives w.r.t. mâ‚™, which are required for moment matching.
        Note: we enforce yâ‚™ Ïµ {-1, +1}
        :param y: observed data (yâ‚™) [scalar]
        :param m: cavity mean (mâ‚™) [scalar]
        :param v: cavity variance (vâ‚™) [scalar]
        :param hyp: dummy variable (Probit has no hyperparameters)
        :param derivatives: if True, return the derivatives of the log partition function w.r.t. mâ‚™ [bool]
        :return:
            lZ: the log partition function, logZâ‚™ [scalar]
            dlZ: first derivative of logZâ‚™ w.r.t. mâ‚™ (if derivatives=True) [scalar]
            d2lZ: second derivative of logZâ‚™ w.r.t. mâ‚™ (if derivatives=True) [scalar]
        """
        y = np.sign(y)  # only allow values of +/-1
        # y[np.where(y == 0)] = -1  # set zeros to -1
        y = np.sign(y - 0.01)  # set zeros to -1
        z = m / np.sqrt(1.0 + v)
        z = z * y  # zâ‚™ = yâ‚™mâ‚™ / âˆš(1 + vâ‚™)
        # logZâ‚™ = log âˆ« Î¦(yâ‚™fâ‚™) ğ“(fâ‚™|mâ‚™,vâ‚™) dfâ‚™
        #       = log Î¦(yâ‚™mâ‚™/âˆš(1 + vâ‚™))  [see Rasmussen & Williams p74]
        lZ, dlp = logphi(z)
        if derivatives:
            # dlogZâ‚™/dmâ‚™ = yâ‚™ dlogÎ¦(zâ‚™)/dmâ‚™ / âˆš(1 + vâ‚™)
            dlZ = y * dlp / np.sqrt(1.0 + v)  # first derivative w.r.t mâ‚™
            # dÂ²logZâ‚™/dmâ‚™Â² = -dlogÎ¦(zâ‚™)/dmâ‚™ (zâ‚™ + dlogÎ¦(zâ‚™)/dmâ‚™) / âˆš(1 + vâ‚™)
            d2lZ = -dlp * (z + dlp) / (1.0 + v)  # second derivative w.r.t mâ‚™
            return lZ, dlZ, d2lZ
        else:
            return lZ


class Erf(Probit):
    pass


class Poisson(Likelihood):
    """
    TODO: not JIT'ed and not tested, just here for an example of how quadrature can be implemented
    The Poisson likelihood:
        p(yâ‚™|fâ‚™) = Poisson(fâ‚™) = Î¼Ê¸ exp(-Î¼) / yâ‚™!
    where Î¼ = g(fâ‚™) = mean = variance is the Poisson intensity.
    yâ‚™ is non-negative integer count data.
    No closed form moment matching is available, se we default to using quadrature.

    Letting Zy = gamma(yâ‚™+1) = yâ‚™!, we get log p(yâ‚™|fâ‚™) = log(g(fâ‚™))yâ‚™ - g(fâ‚™) - log(Zy)
    The larger the intensity Î¼, the stronger the likelihood resembles a Gaussian
    since skewness = 1/sqrt(Î¼) and kurtosis = 1/Î¼.
    Two possible link functions:
    'exp':      link(fâ‚™) = exp(fâ‚™),         we have p(yâ‚™|fâ‚™) = exp(fâ‚™yâ‚™-exp(fâ‚™))            / Zy.
    'logistic': link(fâ‚™) = log(1+exp(fâ‚™))), we have p(yâ‚™|fâ‚™) = logÊ¸(1+exp(fâ‚™)))(1+exp(fâ‚™)) / Zy.
    """
    def __init__(self, hyp=None, link='exp'):
        """
        :param hyp: None. This likelihood model has no hyperparameters
        :param link: link function, either 'exp' or 'logistic'
        """
        super().__init__(hyp=hyp)
        if link is 'exp':
            self.link = lambda mu: np.exp(mu)
        elif link is 'logistic':
            self.link = lambda mu: np.log(1.0 + np.exp(mu))
        else:
            raise NotImplementedError('link function not implemented')

    def evaluate_likelihood(self, y, f):
        """
        Evaluate the Poisson likelihood:
            p(yâ‚™|fâ‚™) = Poisson(fâ‚™) = Î¼Ê¸ exp(-Î¼) / yâ‚™!
        for Î¼ = g(fâ‚™), where g() is the link function (exponential or logisitc)
        We use the gamma function to evaluate yâ‚™! = gamma(yâ‚™ + 1)
        Can be used to evaluate Q quadrature points when performing moment matching
        :param y: observed data (yâ‚™) [scalar]
        :param f: latent function value (fâ‚™) [Q, 1]
        :return:
            Poisson(fâ‚™) = Î¼Ê¸ exp(-Î¼) / yâ‚™! [Q, 1]
        """
        mu = self.link(f)
        return mu**y * np.exp(-mu) / np.exp(gammaln(y + 1))

    def evaluate_log_likelihood(self, y, f):
        """
        Evaluate the Poisson log-likelihood:
            log p(yâ‚™|fâ‚™) = log Poisson(fâ‚™) = log(Î¼Ê¸ exp(-Î¼) / yâ‚™!)
        for Î¼ = g(fâ‚™), where g() is the link function (exponential or logisitc)
        We use the gamma function to evaluate yâ‚™! = gamma(yâ‚™ + 1)
        Can be used to evaluate Q quadrature points when performing moment matching
        :param y: observed data (yâ‚™) [scalar]
        :param f: latent function value (fâ‚™) [Q, 1]
        :return:
            log Poisson(fâ‚™) = log(Î¼Ê¸ exp(-Î¼) / yâ‚™!) [Q, 1]
        """
        mu = self.link(f)
        return y * np.log(mu) - mu - gammaln(y + 1)

    def moment_match(self, y, m, v, hyp=None, derivatives=True, num_quad_points=20):
        """
        Perform moment matching via Gauss-Hermite quadrature
        Moment matching invloves computing the log partition function, logZâ‚™, and its derivatives w.r.t. the cavity mean
            logZâ‚™ = log âˆ« p(yâ‚™|fâ‚™) ğ“(fâ‚™|mâ‚™,vâ‚™) dfâ‚™ = E[p(yâ‚™|fâ‚™)]
        :param y: observed data (yâ‚™) [scalar]
        :param m: cavity mean (mâ‚™) [scalar]
        :param v: cavity variance (vâ‚™) [scalar]
        :param hyp: dummy variable
        :param derivatives: if True, return the derivatives of the log partition function w.r.t. mâ‚™ [bool]
        :param num_quad_points: the number of Gauss-Hermite sigma points to use during quadrature [scalar]
        :return:
            lZ: the log partition function, logZâ‚™  [scalar]
            dlZ: first derivative of logZâ‚™ w.r.t. mâ‚™ (if derivatives=True)  [scalar]
            d2lZ: second derivative of logZâ‚™ w.r.t. mâ‚™ (if derivatives=True)  [scalar]
        """
        x, w = np.polynomial.hermite.hermgauss(num_quad_points)  # Gauss-Hermite sigma points and weights
        w = w / np.sqrt(pi)  # scale weights by 1/âˆšÏ€
        sigma_points = np.sqrt(2) * np.sqrt(v) * x + m  # scale locations according to cavity dist.
        # pre-compute wáµ¢ p(yâ‚™|xáµ¢âˆš(2vâ‚™) + mâ‚™)
        weighted_likelihood_eval = w * self.evaluate_likelihood(y, sigma_points)

        # a different approach, based on the log-likelihood, which can be more stable:
        # ll = self.evaluate_log_likelihood(y, sigma_points)
        # lmax = np.max(ll)
        # weighted_likelihood_eval = np.exp(lmax) * w * np.exp(ll - lmax)

        # Compute partition function via quadrature:
        # Zâ‚™ = âˆ« p(yâ‚™|fâ‚™) ğ“(fâ‚™|mâ‚™,vâ‚™) dfâ‚™
        #    â‰ˆ âˆ‘áµ¢ wáµ¢ p(yâ‚™|xáµ¢âˆš(2vâ‚™) + mâ‚™)
        Z = np.sum(
            weighted_likelihood_eval
        )
        lZ = np.log(Z)
        if derivatives:
            Zinv = 1.0 / Z
            # Compute derivative of partition function via quadrature:
            # dZâ‚™/dmâ‚™ = âˆ« (fâ‚™-mâ‚™) vâ‚™â»Â¹ p(yâ‚™|fâ‚™) ğ“(fâ‚™|mâ‚™,vâ‚™) dfâ‚™
            #         â‰ˆ âˆ‘áµ¢ wáµ¢ (fâ‚™-mâ‚™) vâ‚™â»Â¹ p(yâ‚™|xáµ¢âˆš(2vâ‚™) + mâ‚™)
            dZ = np.sum(
                (sigma_points - m) / v
                * weighted_likelihood_eval
            )
            # dlogZâ‚™/dmâ‚™ = (dZâ‚™/dmâ‚™) / Zâ‚™
            dlZ = Zinv * dZ
            # Compute second derivative of partition function via quadrature:
            # dÂ²Zâ‚™/dmâ‚™Â² = âˆ« [(fâ‚™-mâ‚™)Â² vâ‚™â»Â² - vâ‚™â»Â¹] p(yâ‚™|fâ‚™) ğ“(fâ‚™|mâ‚™,vâ‚™) dfâ‚™
            #           â‰ˆ âˆ‘áµ¢ wáµ¢ [(fâ‚™-mâ‚™)Â² vâ‚™â»Â² - vâ‚™â»Â¹] p(yâ‚™|xáµ¢âˆš(2vâ‚™) + mâ‚™)
            d2Z = np.sum(
                ((sigma_points - m)**2 / v**2 - 1.0 / v)
                * weighted_likelihood_eval
            )
            # dÂ²logZâ‚™/dmâ‚™Â² = d[(dZâ‚™/dmâ‚™) / Zâ‚™]/dmâ‚™
            #              = (dÂ²Zâ‚™/dmâ‚™Â² * Zâ‚™ - (dZâ‚™/dmâ‚™)Â²) / Zâ‚™Â²
            #              = dÂ²Zâ‚™/dmâ‚™Â² / Zâ‚™ - (dlogZâ‚™/dmâ‚™)Â²
            d2lZ = -dlZ**2 + Zinv * d2Z
            return lZ, dlZ, d2lZ
        else:
            return lZ


def logphi(z):
    """
    Calculate the log Gaussian CDF, used for closed form moment matching when the EP power is 1,
        logÎ¦(z) = log[(1 + erf(z / âˆš2)) / 2]
    for erf(z) = (2/âˆšÏ€) âˆ« exp(-xÂ²) dx, where the integral is over [0, z]
    and its derivative w.r.t. z
        dlogÎ¦(z)/dz = ğ“(z|0,1) / Î¦(z)
    :param z: input value, typically z = (my) / âˆš(1 + v) [scalar]
    :return:
        lp: logÎ¦(z) [scalar]
        dlp: dlogÎ¦(z)/dz [scalar]
    """
    z = np.real(z)
    # erfc(z) = 1 - erf(z) is the complementary error function
    lp = np.log(erfc(-z / np.sqrt(2.0)) / 2.0)  # log Î¦(z)
    dlp = np.exp(-z * z / 2.0 - lp) / np.sqrt(2.0 * pi)  # derivative w.r.t. z
    return lp, dlp
